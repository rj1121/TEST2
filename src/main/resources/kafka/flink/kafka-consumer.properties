zk.connect=192.168.44.206:2181/kafka

#broker list
bootstrap.servers=192.168.44.206:9092

#kafka message 序列化 IntegerDeserializer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

#消费组
group.id=qf-kafka-demo

#request.timeout.ms should be greater than session.timeout.ms and fetch.max.wait.ms
request.timeout.ms=60000

#consumer-kafka(broker controller)( <= 1/3 * session.timeout.ms)
heartbeat.interval.ms=15000

#consumer group
#broker group.min.session.timeout.ms(6000) < ? < group.max.session.timeout.ms(30,0000)
session.timeout.ms=40000

#consumer
fetch.max.wait.ms=5000

##fetch min
fetch.min.bytes=0

#fetch.max(message.max.bytes=1000012 10m, producer max.request.size=1048576 10m)
fetch.max.bytes=1000012

# (broker message.max.bytes=1000012 10m )
max.partition.fetch.bytes=1000012

#offset [latest, earliest, none]
auto.offset.reset=latest

#kafka commit
enable.auto.commit=false
auto.commit.interval.ms= 2000

#consumer
#max.poll.interval.ms=300000

#consumer
#max.poll.records=500

#compression type=none, gzip, snappy, lz4, producer
#compression.type=snappy

#consumer producer receive.buffer.bytes=32768
#receive.buffer.bytes=65536

#consumer
#send.buffer.bytes=131072

#broker
#metadata.max.age.ms=300000

#consumer
#reconnect.backoff.ms=50



